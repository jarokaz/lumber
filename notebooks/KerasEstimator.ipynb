{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Model, Input\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import Adadelta\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(serialized):\n",
    "    # Define a dict with the schema reflecting the data in the TFRecords file\n",
    "    features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    \n",
    "    # Parse the serialized data\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "    \n",
    "    # Get the image as raw bytes\n",
    "    image_raw = parsed_example['image']\n",
    "    \n",
    "    # Convert the raw bytes to tensorflow datatypes\n",
    "    image = tf.decode_raw(image_raw, tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # Get the label\n",
    "    label = parsed_example['label']\n",
    "    \n",
    "    # Return the image and label as correct data types\n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=32, buffer_size=2048):\n",
    "    # Create a TensorFlow Dataset-object which has functionality for reading and shuffling data \n",
    "    # from TFREcords files\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    \n",
    "    # Start building the pipeline\n",
    "    # Parse\n",
    "    dataset = dataset.map(parse)\n",
    "    \n",
    "    # Shuffle when training\n",
    "    if train:\n",
    "        dataset = dataset.shuffle(buffer_size = buffer_size)\n",
    "        # Allow infinite reading of the data\n",
    "        num_repeat = None\n",
    "    else:\n",
    "        num_repeat = 1\n",
    "        \n",
    "    # Repeat the dataset the given number of times\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    \n",
    "    # Set the batch size\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "    \n",
    "    return {'image':images_batch}, labels_batch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfrecords_train = '../data/tfrecords/training.tfrecords'\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfrecords_test = '../data/tfrecords/validation.tfrecords'\n",
    "def test_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = np.array(Image.open('../data/validation/st1179_sound_9.PNG'))\n",
    "image2 = np.array(Image.open('../data/validation/st1179_dry_knot_3.PNG'))\n",
    "some_images = np.array([image1, image2])/255\n",
    "some_images = np.reshape(some_images, (2, 37632))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"image\": some_images.astype(np.float32)},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(labels, 7)\n",
    "x_train = images/255\n",
    "\n",
    "inputs = Input(shape=(112, 112, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "y = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=y)\n",
    "\n",
    "model.compile(optimizer = Adadelta(), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"learning_rate\": 1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-35d571ac161a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m odel = tf.estimator.Estimator(model_fn=model_fn,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                model_dir=\"../checkpoints\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_fn' is not defined"
     ]
    }
   ],
   "source": [
    "odel = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=\"../checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(input_fn=train_input_fn, steps=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array(list(predictions))\n",
    "cls_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
